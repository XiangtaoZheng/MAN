# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.
"""
Implements the Generalized R-CNN framework
"""
import time
import numpy as np
import cv2
from PIL import Image
import itertools
import torch
from torch import nn
from torchvision.transforms import functional as F

from maskrcnn_benchmark.structures.image_list import to_image_list
from maskrcnn_benchmark.structures.image_list import ImageList


from ..cyclegan import networks
from ..cyclegan.image_pool import ImagePool
from ..backbone import build_backbone
from ..rpn.rpn import build_rpn
from ..roi_heads.roi_heads import build_roi_heads
from ..da_heads.da_heads import build_da_heads


class GeneralizedRCNN(nn.Module):
    """
    Main class for Generalized R-CNN. Currently supports boxes and masks.
    It consists of three main parts:
    - backbone
    - rpn
    - heads: takes the features + the proposals from the RPN and computes
        detections / masks from it.
    """

    def __init__(self, cfg):
        super(GeneralizedRCNN, self).__init__()

        self.mean = cfg.INPUT.PIXEL_MEAN
        self.std = cfg.INPUT.PIXEL_STD

        self.netG_A = networks.define_G()
        self.netG_B = networks.define_G()

        self.netD_A = networks.define_D()
        self.netD_B = networks.define_D()

        self.backbone = build_backbone(cfg)
        self.rpn = build_rpn(cfg)
        self.roi_heads = build_roi_heads(cfg)
        self.da_heads = build_da_heads(cfg)

        self.id = 0

        if self.training:
            self.fake_A_pool = ImagePool(50)  # create image buffer to store previously generated images
            self.fake_B_pool = ImagePool(50)  # create image buffer to store previously generated images
            # define loss functions
            self.criterionGAN = networks.GANLoss('lsgan')  # define GAN loss.
            self.criterionCycle = torch.nn.L1Loss()
            self.criterionIdt = torch.nn.L1Loss()
            # initialize optimizers; schedulers will be automatically created by function <BaseModel.setup>.
            self.optimizers = []
            self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()), lr=0.0002, betas=(0.5, 0.999))
            self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()), lr=0.0002, betas=(0.5, 0.999))
            self.optimizers.append(self.optimizer_G)
            self.optimizers.append(self.optimizer_D)

    def set_requires_grad(self, nets, requires_grad=False):
        """Set requies_grad=Fasle for all the networks to avoid unnecessary computations
        Parameters:
            nets (network list)   -- a list of networks
            requires_grad (bool)  -- whether the networks require gradients or not
        """
        if not isinstance(nets, list):
            nets = [nets]
        for net in nets:
            if net is not None:
                for param in net.parameters():
                    param.requires_grad = requires_grad

    def backward_D_basic(self, netD, real, fake):
        """Calculate GAN loss for the discriminator

        Parameters:
            netD (network)      -- the discriminator D
            real (tensor array) -- real images
            fake (tensor array) -- images generated by a generator

        Return the discriminator loss.
        We also call loss_D.backward() to calculate the gradients.
        """
        # Real
        pred_real = netD(real)
        loss_D_real = self.criterionGAN(pred_real, True)
        # Fake
        pred_fake = netD(fake.detach())
        loss_D_fake = self.criterionGAN(pred_fake, False)
        # Combined loss and calculate gradients
        loss_D = (loss_D_real + loss_D_fake) * 0.5
        loss_D.backward(retain_graph=True)
        return loss_D

    def backward_D_A(self):
        """Calculate GAN loss for discriminator D_A"""
        fake_B = self.fake_B_pool.query(self.fake_B)
        self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)

    def backward_D_B(self):
        """Calculate GAN loss for discriminator D_B"""
        fake_A = self.fake_A_pool.query(self.fake_A)
        self.loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)

    def backward_G(self):
        """Calculate the loss for generators G_A and G_B"""
        # lambda_idt = self.opt.lambda_identity
        lambda_idt = 0.1
        # lambda_A = self.opt.lambda_A
        # lambda_B = self.opt.lambda_B
        lambda_A = 10.0
        lambda_B = 10.0
        # Identity loss
        if lambda_idt > 0:
            # G_A should be identity if real_B is fed: ||G_A(B) - B||
            self.idt_A = self.netG_A(self.real_B)
            self.loss_idt_A = self.criterionIdt(self.idt_A, self.real_B) * lambda_B * lambda_idt
            # G_B should be identity if real_A is fed: ||G_B(A) - A||
            self.idt_B = self.netG_B(self.real_A)
            self.loss_idt_B = self.criterionIdt(self.idt_B, self.real_A) * lambda_A * lambda_idt
        else:
            self.loss_idt_A = 0
            self.loss_idt_B = 0

        # GAN loss D_A(G_A(A))
        self.loss_G_A = self.criterionGAN(self.netD_A(self.fake_B), True)
        # GAN loss D_B(G_B(B))
        self.loss_G_B = self.criterionGAN(self.netD_B(self.fake_A), True)
        # Forward cycle loss || G_B(G_A(A)) - A||
        self.loss_cycle_A = self.criterionCycle(self.rec_A, self.real_A) * lambda_A
        # Backward cycle loss || G_A(G_B(B)) - B||
        self.loss_cycle_B = self.criterionCycle(self.rec_B, self.real_B) * lambda_B
        # combined loss and calculate gradients
        self.loss_G = self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B + self.loss_idt_A + self.loss_idt_B
        self.loss_G.backward(retain_graph=True)

    def tensor2im(self, input_image, imtype=np.uint8):
        """"Converts a Tensor array into a numpy image array.

        Parameters:
            input_image (tensor) --  the input image tensor array
            imtype (type)        --  the desired type of the converted numpy array
        """
        if not isinstance(input_image, np.ndarray):
            if isinstance(input_image, torch.Tensor):  # get the data from a variable
                image_tensor = input_image.data
            else:
                return input_image
            image_numpy = image_tensor[0].cpu().float().numpy()  # convert it into a numpy array
            if image_numpy.shape[0] == 1:  # grayscale to RGB
                image_numpy = np.tile(image_numpy, (3, 1, 1))
            image_numpy -= np.min(image_numpy)
            image_numpy /= np.max(image_numpy)
            image_numpy = (np.transpose(image_numpy, (1, 2, 0))) * 255.0  # post-processing: tranpose and scaling
            # image_numpy[image_numpy < 0] = 0
            # image_numpy[image_numpy > 255] = 255
        else:  # if it is a numpy array, do nothing
            image_numpy = input_image
        return image_numpy.astype(imtype)

    def save_image(self, image_numpy, image_path, aspect_ratio=1.0):
        """Save a numpy image to the disk

        Parameters:
            image_numpy (numpy array) -- input numpy array
            image_path (str)          -- the path of the image
        """

        image_pil = Image.fromarray(image_numpy)
        h, w, _ = image_numpy.shape

        if aspect_ratio > 1.0:
            image_pil = image_pil.resize((h, int(w * aspect_ratio)), Image.BICUBIC)
        if aspect_ratio < 1.0:
            image_pil = image_pil.resize((int(h / aspect_ratio), w), Image.BICUBIC)
        image_pil.save(image_path)

    def optimize_parameters(self):

        # G_A and G_B
        self.set_requires_grad([self.netD_A, self.netD_B, self.backbone, self.rpn, self.roi_heads, self.da_heads], False)  # Ds require no gradients when optimizing Gs
        self.optimizer_G.zero_grad()  # set G_A and G_B's gradients to zero
        self.backward_G()  # calculate gradients for G_A and G_B
        self.optimizer_G.step()  # update G_A and G_B's weights
        # D_A and D_B
        self.set_requires_grad([self.netD_A, self.netD_B], True)
        self.optimizer_D.zero_grad()  # set D_A and D_B's gradients to zero
        self.backward_D_A()  # calculate gradients for D_A
        self.backward_D_B()  # calculate graidents for D_B
        self.optimizer_D.step()  # update D_A and D_B's weights
        self.set_requires_grad([self.netD_A, self.netD_B, self.backbone, self.rpn, self.roi_heads, self.da_heads], True)

    # def forward(self, images, targets=None):
    def forward(self, images, source_images=None, target_images=None, targets=None):

        """
        Arguments:
            images (list[Tensor] or ImageList): images to be processed
            targets (list[BoxList]): ground-truth boxes present in the image (optional)

        Returns:
            result (list[BoxList] or dict[Tensor]): the output from the model.
                During training, it returns a dict[Tensor] which contains the losses.
                During testing, it returns list[BoxList] contains additional fields
                like `scores`, `labels` and `mask` (for Mask R-CNN models).

        """
        if self.training and targets is None:
            raise ValueError("In training mode, targets should be passed")
        # t1 = time.time()
        if self.training:
            self.real_A = source_images.tensors
            self.real_B = target_images.tensors
            self.fake_B = self.netG_A(self.real_A)  # G_A(A)
            self.rec_A = self.netG_B(self.fake_B)   # G_B(G_A(A))
            self.fake_A = self.netG_B(self.real_B)  # G_B(B)
            self.rec_B = self.netG_A(self.fake_A)   # G_A(G_B(B))
            self.optimize_parameters()
            fake = ImageList(self.fake_B, source_images.image_sizes)
            images = (fake + target_images)
            # fake = ImageList(self.fake_A, target_images.image_sizes)
            # images = (source_images + fake)
            # A = ImageList(torch.cat((self.real_A, self.fake_B), 1), source_images.image_sizes)
            # B = ImageList(torch.cat((self.fake_A, self.real_B), 1), target_images.image_sizes)
            # images = (A + B)
        # else:
        #     images.tensors = torch.cat((self.netG_B(images.tensors), images.tensors), 1)
        # else:
        #     self.real_A = images.tensors
        #     self.fake_B = self.netG_A(self.real_A)
        #     im = self.tensor2im(self.fake_B)
        #     self.id += 1
        #     im_1 = self.tensor2im(self.real_A)
        #     self.save_image(im, 'CycleGAN/' + str(self.id) + '_2.jpg')
        #     self.save_image(im_1, 'CycleGAN/' + str(self.id) + '_1.jpg')
        #     # if self.id == 6:
        #     #     print('ok')
        # else:
        #     images.tensors = self.netG_B(images.tensors)
        # t2 = time.time()
        # print("T1:%.6f"%(t2-t1))
        features = self.backbone(images.tensors)

        # im_map = images.tensors.reshape(3, images.tensors.shape[2], images.tensors.shape[3])
        # # im_map = torch.mean(im_data, dim=1)
        # im_map = im_map.permute(1, 2, 0)
        # im_map = im_map.cpu().detach().numpy()
        # im_map -= np.min(im_map)
        # im_map /= np.max(im_map)
        # im_map = cv2.resize(im_map, (800, 800)) * 255
        # # im_map = cv2.cvtColor(im_map, cv2.COLOR_BGR2GRAY)
        # # im_map = np.uint8(im_map)
        # feat_map = torch.mean(features[0], dim=1)
        # feat_map = feat_map.permute(1, 2, 0)
        # feat_map = feat_map.cpu().detach().numpy()
        # feat_map -= np.min(feat_map)
        # feat_map /= np.max(feat_map)
        # feat_map = cv2.resize(feat_map, (800, 800))
        # feat_map = cv2.applyColorMap(np.uint8(255 * feat_map), cv2.COLORMAP_JET)
        # # feat_map = im_map * 0.7 + feat_map * 0.3

        proposals, proposal_losses = self.rpn(images, features, targets)
        da_losses = {}
        if self.roi_heads:
            x, result, detector_losses, da_ins_feas, da_ins_labels = \
                self.roi_heads(features, proposals, targets)
            # for i in range(len(features)):
            #     print(features[i].shape)
            # print(da_ins_feas.shape, da_ins_labels.shape)
            if self.da_heads:
                da_losses = self.da_heads(features, da_ins_feas, da_ins_labels, targets)

        else:
            # RPN-only models don't have roi_heads
            x = features
            result = proposals
            detector_losses = {}
        t6 = time.time()
        # print("T4:%.6f" % (t6 - t2))

        if self.training:
            losses = {}
            losses.update(detector_losses)
            losses.update(proposal_losses)
            losses.update(da_losses)
            return losses

        return result
        # if self.training:
        #     return result
        # else:
        #     return result, feat_map, im_map
